{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##  Chunking - Optimizing Vector Database Data Preparation",
   "id": "37e2b6fcaa9eceee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Character/Token Based Chunking\n",
    "- Recursive Character/Token Based Chunking\n",
    "- Semantic Chunking\n",
    "- Cluster Semantic Chunking\n",
    "- LLM Semantic Chunking"
   ],
   "id": "fef92004fee37f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### The Chunking Evaluation Repo"
   ],
   "id": "f08e321cbd8bd095"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-25T19:37:09.208054Z",
     "start_time": "2025-05-25T19:37:00.196191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/brandonstarxel/chunking_evaluation.git"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:51:14.639976Z",
     "start_time": "2025-05-27T06:51:12.880774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Main Chunking Functions\n",
    "from chunking_evaluation.chunking import (\n",
    "    ClusterSemanticChunker,\n",
    "    LLMSemanticChunker,\n",
    "    FixedTokenChunker,\n",
    "    RecursiveTokenChunker,\n",
    "    KamradtModifiedChunker\n",
    ")\n",
    "# Additional Dependencies\n",
    "import tiktoken\n",
    "from chromadb.utils import embedding_functions\n",
    "from chunking_evaluation.utils import openai_token_count\n",
    "import os"
   ],
   "id": "80cee3e71e61a37",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pride and Prejudice by Jane Austen, available for free from Project Gutenberg, will be used. It consists of 476 pages of text or 175,651 tokens.",
   "id": "f9a4520e787371fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:51:16.972127Z",
     "start_time": "2025-05-27T06:51:16.965127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "with open(\"./pride_and_prejudice.txt\", 'r', encoding='utf-8') as file:\n",
    "        document = file.read()\n",
    "\n",
    "print(\"First 1000 Characters: \", document[:1000])"
   ],
   "id": "e4eff6c657670144",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 1000 Characters:  ﻿The Project Gutenberg eBook of Pride and Prejudice\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this eBook.\n",
      "\n",
      "Title: Pride and Prejudice\n",
      "\n",
      "Author: Jane Austen\n",
      "\n",
      "Release date: June 1, 1998 [eBook #1342]\n",
      "                Most recently updated: June 17, 2024\n",
      "\n",
      "Language: English\n",
      "\n",
      "Credits: Chuck Greif and the Online Distributed Proofreading Team at http://www.pgdp.net (This file was produced from images available at The Internet Archive)\n",
      "\n",
      "\n",
      "*** START OF THE PROJECT GUTENBERG EBOOK PRIDE AND PREJUDICE ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                            [Illustration:\n",
      "\n",
      "                             GEORGE ALLEN\n",
      "                   \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### **Helper Function for Analyzing Chunking!**",
   "id": "7a6e67188231a75f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- **Display Chunk Count**: _The function prints the length of the provided chunks list (i.e., the number of chunks)._\n",
    "- **Examine Specific Chunks**: _It prints the 200th and 201st chunks (indices 199 and 200)._\n",
    "\n",
    "- **Overlap Analysis**: _It identifies overlapping text between the 200th and 201st chunks, checked in two modes._\n",
    "    + **Character-Based** (use_tokens=False): _Searches for a common substring between the two chunks._\n",
    "    + **Token-Based** (use_tokens=True): _Uses the tiktoken library to tokenize the text and checks for token overlap._"
   ],
   "id": "9acade2a27163aaf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:51:21.125394Z",
     "start_time": "2025-05-27T06:51:21.117188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def analyze_chunks(chunks, use_tokens=False):\n",
    "    # Print the chunks of interest\n",
    "    print(\"\\nNumber of Chunks:\", len(chunks))\n",
    "    print(\"\\n\", \"=\"*50, \"200th Chunk\", \"=\"*50,\"\\n\", chunks[199])\n",
    "    print(\"\\n\", \"=\"*50, \"201st Chunk\", \"=\"*50,\"\\n\", chunks[200])\n",
    "\n",
    "    chunk1, chunk2 = chunks[199], chunks[200]\n",
    "\n",
    "    if use_tokens:\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        tokens1 = encoding.encode(chunk1)\n",
    "        tokens2 = encoding.encode(chunk2)\n",
    "\n",
    "        # Find overlapping tokens\n",
    "        for i in range(len(tokens1), 0, -1):\n",
    "            if tokens1[-i:] == tokens2[:i]:\n",
    "                overlap = encoding.decode(tokens1[-i:])\n",
    "                print(\"\\n\", \"=\"*50, f\"\\nOverlapping text ({i} tokens):\", overlap)\n",
    "                return\n",
    "        print(\"\\nNo token overlap found\")\n",
    "    else:\n",
    "        # Find overlapping characters\n",
    "        for i in range(min(len(chunk1), len(chunk2)), 0, -1):\n",
    "            if chunk1[-i:] == chunk2[:i]:\n",
    "                print(\"\\n\", \"=\"*50, f\"\\nOverlapping text ({i} chars):\", chunk1[-i:])\n",
    "                return\n",
    "        print(\"\\nNo character overlap found\")"
   ],
   "id": "bbcc76f905996f8e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### <font color='orange'>**Character Text Splitting**</font>",
   "id": "87aedf2a6654eac8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "_The simplest form of chunking would be simply counting some number of characters and splitting at that count._",
   "id": "e5a918e49aec94af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:51:26.070636Z",
     "start_time": "2025-05-27T06:51:26.066442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chunk_text(document, chunk_size, overlap):\n",
    "    chunks = []\n",
    "    stride = chunk_size - overlap\n",
    "    current_idx = 0\n",
    "\n",
    "    while current_idx < len(document):\n",
    "        # Take chunk_size characters starting from current_idx\n",
    "        chunk = document[current_idx:current_idx + chunk_size]\n",
    "        if not chunk:  # Break if we're out of text\n",
    "            break\n",
    "        chunks.append(chunk)\n",
    "        current_idx += stride  # Move forward by stride\n",
    "\n",
    "    return chunks"
   ],
   "id": "4a6cbdaa59901ad",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Chunk size of `400` Characters, `no overlap`",
   "id": "1adcbc81416cd4f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:51:30.952872Z",
     "start_time": "2025-05-27T06:51:30.948814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "character_chunks = chunk_text(document, chunk_size=400, overlap=0)\n",
    "\n",
    "analyze_chunks(character_chunks)"
   ],
   "id": "c341c686cb511775",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Chunks: 1871\n",
      "\n",
      " ================================================== 200th Chunk ================================================== \n",
      " ty to their aunt, and\n",
      "to a milliner’s shop just over the way. The two youngest of the family,\n",
      "Catherine and Lydia, were particularly frequent in these attentions:\n",
      "their minds were more vacant than their sisters’, and when nothing\n",
      "better offered, a walk to Meryton was necessary to amuse their morning\n",
      "hours and furnish conversation for the evening; and, however bare of\n",
      "news the country in general mi\n",
      "\n",
      " ================================================== 201st Chunk ================================================== \n",
      " ght be, they always contrived to learn\n",
      "some from their aunt. At present, indeed, they were well supplied both\n",
      "with news and happiness by the recent arrival of a militia regiment in\n",
      "the neighbourhood; it was to remain the whole winter, and Meryton was\n",
      "the head-quarters.\n",
      "\n",
      "Their visits to Mrs. Philips were now productive of the most interesting\n",
      "intelligence. Every day added something to their knowled\n",
      "\n",
      "No character overlap found\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Chunk size of `800` Characters, `400` overlap",
   "id": "4a30f3b820d5e60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:51:34.463697Z",
     "start_time": "2025-05-27T06:51:34.458423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "character_overlap_chunks = chunk_text(document, chunk_size=800, overlap=400)\n",
    "\n",
    "analyze_chunks(character_overlap_chunks)"
   ],
   "id": "7b51901afe9e42f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Chunks: 1871\n",
      "\n",
      " ================================================== 200th Chunk ================================================== \n",
      " ty to their aunt, and\n",
      "to a milliner’s shop just over the way. The two youngest of the family,\n",
      "Catherine and Lydia, were particularly frequent in these attentions:\n",
      "their minds were more vacant than their sisters’, and when nothing\n",
      "better offered, a walk to Meryton was necessary to amuse their morning\n",
      "hours and furnish conversation for the evening; and, however bare of\n",
      "news the country in general might be, they always contrived to learn\n",
      "some from their aunt. At present, indeed, they were well supplied both\n",
      "with news and happiness by the recent arrival of a militia regiment in\n",
      "the neighbourhood; it was to remain the whole winter, and Meryton was\n",
      "the head-quarters.\n",
      "\n",
      "Their visits to Mrs. Philips were now productive of the most interesting\n",
      "intelligence. Every day added something to their knowled\n",
      "\n",
      " ================================================== 201st Chunk ================================================== \n",
      " ght be, they always contrived to learn\n",
      "some from their aunt. At present, indeed, they were well supplied both\n",
      "with news and happiness by the recent arrival of a militia regiment in\n",
      "the neighbourhood; it was to remain the whole winter, and Meryton was\n",
      "the head-quarters.\n",
      "\n",
      "Their visits to Mrs. Philips were now productive of the most interesting\n",
      "intelligence. Every day added something to their knowledge of the\n",
      "officers’ names and connections. Their lodgings were not long a secret,\n",
      "and at length they began to know the officers themselves. Mr. Philips\n",
      "visited them all, and this opened to his nieces a source of felicity\n",
      "unknown before. They could talk of nothing but officers; and Mr.\n",
      "Bingley’s large fortune, the mention of which gave animation to their\n",
      "mother, was worthless in their eyes when opp\n",
      "\n",
      " ================================================== \n",
      "Overlapping text (400 chars): ght be, they always contrived to learn\n",
      "some from their aunt. At present, indeed, they were well supplied both\n",
      "with news and happiness by the recent arrival of a militia regiment in\n",
      "the neighbourhood; it was to remain the whole winter, and Meryton was\n",
      "the head-quarters.\n",
      "\n",
      "Their visits to Mrs. Philips were now productive of the most interesting\n",
      "intelligence. Every day added something to their knowled\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### <font color='orange'>**Token Text Splitting**</font>",
   "id": "352315e316a1504e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "But language models (the end users of chunked text usually) don't operate at the character level. Instead they use tokens, or common sequences of characters that represent frequent words, word pieces, and subwords. For example, the word 'hamburger' when ran through GPT-4's tokenizer is split into the tokens ['h', 'amburger']. Common words like 'the' or 'and' are typically single tokens.\n",
    "\n",
    "This means character-based splitting isn't ideal because:\n",
    "\n",
    "    1. A 500-character chunk might contain anywhere from 100-500 tokens depending on the text\n",
    "    2. Different languages and character sets encode to very different numbers of tokens\n",
    "    3. We might hit token limits in our LLM without realizing it\n",
    "\n",
    "A good visualizer of tokenization is available [on OpenAI's platform](https://platform.openai.com/tokenizer)\n",
    "\n",
    "Tokenizers like 'cl100k_base' implement Byte-Pair Encoding (BPE) - a compression algorithm that creates a vocabulary by iteratively merging the most frequent pairs of bytes or characters. The '100k' refers to its vocab size, determining the balance between compression and representation granularity.\n",
    "\n",
    "When talking to a language model, the first step is tokenizing the text so that it can be processed by the underlying neural network. The LLM outputs tokens which are decoded back into words."
   ],
   "id": "abc3e5ae518e0c85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:51:39.845860Z",
     "start_time": "2025-05-27T06:51:39.714934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "\n",
    "# Loading cl100k_base tokenizer\n",
    "encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# Text Example\n",
    "text = \"hamburger\"\n",
    "tokens = encoder.encode(text)\n",
    "\n",
    "print(\"Tokens:\", tokens)"
   ],
   "id": "73459b68911e6f97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: [71, 47775]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:51:42.133242Z",
     "start_time": "2025-05-27T06:51:42.129240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(len(tokens)):\n",
    "    print(f\"Token {i+1}:\", encoder.decode([tokens[i]]))\n",
    "\n",
    "print(\"Full Decoding: \", encoder.decode(tokens))"
   ],
   "id": "adeeb3c0627e066e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 1: h\n",
      "Token 2: amburger\n",
      "Full Decoding:  hamburger\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### **Helper Function for Counting Tokens**",
   "id": "95a819f5020c5f19"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:51:44.411705Z",
     "start_time": "2025-05-27T06:51:44.407985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def count_tokens(text, model=\"cl100k_base\"):\n",
    "    \"\"\"Count tokens in a text string using tiktoken\"\"\"\n",
    "    encoder = tiktoken.get_encoding(model)\n",
    "    return print(f\"Number of tokens: {len(encoder.encode(text))}\")"
   ],
   "id": "b92ab03393efe1b0",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Chunk Size of `400` Tokens, `0 Overlap`",
   "id": "2d5be0c6864df63c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:51:46.271270Z",
     "start_time": "2025-05-27T06:51:46.189486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fixed_token_chunker = FixedTokenChunker(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=0,\n",
    "    encoding_name=\"cl100k_base\"\n",
    ")\n",
    "\n",
    "token_chunks = fixed_token_chunker.split_text(document)\n",
    "\n",
    "analyze_chunks(token_chunks, use_tokens=True)"
   ],
   "id": "aa7f27912484ab8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Chunks: 440\n",
      "\n",
      " ================================================== 200th Chunk ================================================== \n",
      "  fortunate as to meet Miss Bennet. The\n",
      "subject was pursued no further, and the gentlemen soon afterwards went\n",
      "away.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[Illustration:\n",
      "\n",
      "“At Church”\n",
      "]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CHAPTER XXXI.\n",
      "\n",
      "\n",
      "[Illustration]\n",
      "\n",
      "Colonel Fitzwilliam’s manners were very much admired at the Parsonage,\n",
      "and the ladies all felt that he must add considerably to the pleasure of\n",
      "their engagements at Rosings. It was some days, however, before they\n",
      "received any invitation thither, for while there were visitors in the\n",
      "house they could not be necessary; and it was not till Easter-day,\n",
      "almost a week after the gentlemen’s arrival, that they were honoured by\n",
      "such an attention, and then they were merely asked on leaving church to\n",
      "come there in the evening. For the last week they had seen very little\n",
      "of either Lady Catherine or her daughter. Colonel Fitzwilliam had called\n",
      "at the Parsonage more than once during the time, but Mr. Darcy they had\n",
      "only seen at church.\n",
      "\n",
      "The invitation was accepted, of course, and at a proper hour they joined\n",
      "the party in Lady Catherine’s drawing-room. Her Ladyship received them\n",
      "civilly, but it was plain that their company was by no means so\n",
      "acceptable as when she could get nobody else; and she was, in fact,\n",
      "almost engrossed by her nephews, speaking to them, especially to Darcy,\n",
      "much more than to any other person in the room.\n",
      "\n",
      "Colonel Fitzwilliam seemed really glad to see them: anything was a\n",
      "welcome relief to him at Rosings; and Mrs. Collins’s pretty friend had,\n",
      "moreover, caught his fancy very much. He now seated himself by her, and\n",
      "talked so agreeably of Kent and Hertfordshire, of travelling and staying\n",
      "at home, of new books and music, that Elizabeth had never been half so\n",
      "well entertained in that room before; and they conversed with so much\n",
      "\n",
      "\n",
      " ================================================== 201st Chunk ================================================== \n",
      " spirit and flow as to draw the attention of Lady Catherine herself, as\n",
      "well as of Mr. Darcy. _His_ eyes had been soon and repeatedly turned\n",
      "towards them with a look of curiosity; and that her Ladyship, after a\n",
      "while, shared the feeling, was more openly acknowledged, for she did not\n",
      "scruple to call out,--\n",
      "\n",
      "“What is that you are saying, Fitzwilliam? What is it you are talking\n",
      "of? What are you telling Miss Bennet? Let me hear what it is.”\n",
      "\n",
      "“We were talking of music, madam,” said he, when no longer able to avoid\n",
      "a reply.\n",
      "\n",
      "“Of music! Then pray speak aloud. It is of all subjects my delight. I\n",
      "must have my share in the conversation, if you are speaking of music.\n",
      "There are few people in England, I suppose, who have more true\n",
      "enjoyment of music than myself, or a better natural taste. If I had ever\n",
      "learnt, I should have been a great proficient. And so would Anne, if her\n",
      "health had allowed her to apply. I am confident that she would have\n",
      "performed delightfully. How does Georgiana get on, Darcy?”\n",
      "\n",
      "Mr. Darcy spoke with affectionate praise of his sister’s proficiency.\n",
      "\n",
      "“I am very glad to hear such a good account of her,” said Lady\n",
      "Catherine; “and pray tell her from me, that she cannot expect to excel,\n",
      "if she does not practise a great deal.”\n",
      "\n",
      "“I assure you, madam,” he replied, “that she does not need such advice.\n",
      "She practises very constantly.”\n",
      "\n",
      "“So much the better. It cannot be done too much; and when I next write\n",
      "to her, I shall charge her not to neglect it on any account. I often\n",
      "tell young ladies, that no excellence in music is to be acquired without\n",
      "constant practice. I have told Miss Bennet several times, that she will\n",
      "never\n",
      "\n",
      "No token overlap found\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:51:49.410358Z",
     "start_time": "2025-05-27T06:51:49.406296Z"
    }
   },
   "cell_type": "code",
   "source": "count_tokens(token_chunks[0])",
   "id": "eb0ac5ec572c35cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 400\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Chunk Size of `400` Tokens, `200` Overlap",
   "id": "9ff4a85ab60e32bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:51:51.410415Z",
     "start_time": "2025-05-27T06:51:51.334952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fixed_token_chunker = FixedTokenChunker(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=200,\n",
    "    encoding_name=\"cl100k_base\"\n",
    ")\n",
    "\n",
    "token_overlap_chunks = fixed_token_chunker.split_text(document)\n",
    "\n",
    "analyze_chunks(token_overlap_chunks, use_tokens=True)"
   ],
   "id": "12fe800f5b9752a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Chunks: 878\n",
      "\n",
      " ================================================== 200th Chunk ================================================== \n",
      "  I _heard_ nothing of his going away when I\n",
      "was at Netherfield. I hope your plans in favour of the ----shire will\n",
      "not be affected by his being in the neighbourhood.”\n",
      "\n",
      "“Oh no--it is not for _me_ to be driven away by Mr. Darcy. If _he_\n",
      "wishes to avoid seeing _me_ he must go. We are not on friendly terms,\n",
      "and it always gives me pain to meet him, but I have no reason for\n",
      "avoiding _him_ but what I might proclaim to all the world--a sense of\n",
      "very great ill-usage, and most painful regrets at his being what he is.\n",
      "His father, Miss Bennet, the late Mr. Darcy, was one of the best men\n",
      "that ever breathed, and the truest friend I ever had; and I can never be\n",
      "in company with this Mr. Darcy without being grieved to the soul by a\n",
      "thousand tender recollections. His behaviour to myself has been\n",
      "scandalous; but I verily believe I could forgive him anything and\n",
      "everything, rather than his disappointing the hopes and disgracing the\n",
      "memory of his father.”\n",
      "\n",
      "Elizabeth found the interest of the subject increase, and listened with\n",
      "all her heart; but the delicacy of it prevented further inquiry.\n",
      "\n",
      "Mr. Wickham began to speak on more general topics, Meryton, the\n",
      "neighbourhood, the society, appearing highly pleased with all that he\n",
      "had yet seen, and speaking of the latter, especially, with gentle but\n",
      "very intelligible gallantry.\n",
      "\n",
      "“It was the prospect of constant society, and good society,” he added,\n",
      "“which was my chief inducement to enter the ----shire. I know it to be a\n",
      "most respectable, agreeable corps; and my friend Denny tempted me\n",
      "further by his account of their present quarters, and the very great\n",
      "attentions and excellent acquaintance Meryton had procured\n",
      "\n",
      " ================================================== 201st Chunk ================================================== \n",
      "  His behaviour to myself has been\n",
      "scandalous; but I verily believe I could forgive him anything and\n",
      "everything, rather than his disappointing the hopes and disgracing the\n",
      "memory of his father.”\n",
      "\n",
      "Elizabeth found the interest of the subject increase, and listened with\n",
      "all her heart; but the delicacy of it prevented further inquiry.\n",
      "\n",
      "Mr. Wickham began to speak on more general topics, Meryton, the\n",
      "neighbourhood, the society, appearing highly pleased with all that he\n",
      "had yet seen, and speaking of the latter, especially, with gentle but\n",
      "very intelligible gallantry.\n",
      "\n",
      "“It was the prospect of constant society, and good society,” he added,\n",
      "“which was my chief inducement to enter the ----shire. I know it to be a\n",
      "most respectable, agreeable corps; and my friend Denny tempted me\n",
      "further by his account of their present quarters, and the very great\n",
      "attentions and excellent acquaintance Meryton had procured them.\n",
      "Society, I own, is necessary to me. I have been a disappointed man, and\n",
      "my spirits will not bear solitude. I _must_ have employment and society.\n",
      "A military life is not what I was intended for, but circumstances have\n",
      "now made it eligible. The church _ought_ to have been my profession--I\n",
      "was brought up for the church; and I should at this time have been in\n",
      "possession of a most valuable living, had it pleased the gentleman we\n",
      "were speaking of just now.”\n",
      "\n",
      "“Indeed!”\n",
      "\n",
      "“Yes--the late Mr. Darcy bequeathed me the next presentation of the best\n",
      "living in his gift. He was my godfather, and excessively attached to me.\n",
      "I cannot do justice to his kindness. He meant to provide for me amply,\n",
      "and thought he had done it; but when the living fell, it was given\n",
      "elsewhere.”\n",
      "\n",
      "“Good heavens!” cried Elizabeth; “but how could _that_ be\n",
      "\n",
      " ================================================== \n",
      "Overlapping text (200 tokens):  His behaviour to myself has been\n",
      "scandalous; but I verily believe I could forgive him anything and\n",
      "everything, rather than his disappointing the hopes and disgracing the\n",
      "memory of his father.”\n",
      "\n",
      "Elizabeth found the interest of the subject increase, and listened with\n",
      "all her heart; but the delicacy of it prevented further inquiry.\n",
      "\n",
      "Mr. Wickham began to speak on more general topics, Meryton, the\n",
      "neighbourhood, the society, appearing highly pleased with all that he\n",
      "had yet seen, and speaking of the latter, especially, with gentle but\n",
      "very intelligible gallantry.\n",
      "\n",
      "“It was the prospect of constant society, and good society,” he added,\n",
      "“which was my chief inducement to enter the ----shire. I know it to be a\n",
      "most respectable, agreeable corps; and my friend Denny tempted me\n",
      "further by his account of their present quarters, and the very great\n",
      "attentions and excellent acquaintance Meryton had procured\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### <font color='orange'>**Recursive Character Text Splitter**</font>",
   "id": "8ca0efe1fa9da692"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "When we write, we naturally separate text into paragraphs, sentences, and other logical units. The recursive character text splitter tries to intelligently split text by looking for natural separators in order, while respecting a maximum character length.\n",
    "\n",
    "First, it makes a complete pass over the entire document using paragraph breaks (\\n\\n), creating an initial set of chunks. Then for any chunks that exceed the size limit, it recursively processes them using progressively smaller separators:\n",
    "\n",
    "    1. First tries to split on paragraph breaks (\\n\\n)\n",
    "    2. If chunks are still too big, tries line breaks (\\n)\n",
    "    3. Then sentence boundaries (., ?, !)\n",
    "    4. Then words ( )\n",
    "    5. Finally, if no other separators work, splits on individual characters (\"\")\n",
    "\n",
    "This way, the splitter preserves as much natural structure as possible - only drilling down to smaller separators when necessary to meet the size limit. A chunk that's already small enough stays intact, while larger chunks get progressively broken down until they fit."
   ],
   "id": "b55abe0f1b19d779"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Chunk Size of `800` Characters, `0` Overlap**",
   "id": "ac5456ae1224cf05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:51:55.835195Z",
     "start_time": "2025-05-27T06:51:55.824142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "recursive_character_chunker = RecursiveTokenChunker(\n",
    "    chunk_size=800,  # Character Length\n",
    "    chunk_overlap=0,  # Overlap\n",
    "    length_function=len,  # Character length with len()\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"?\", \"!\", \" \", \"\"] # According to Research\n",
    ")\n",
    "\n",
    "recursive_character_chunks = recursive_character_chunker.split_text(document)\n",
    "analyze_chunks(recursive_character_chunks, use_tokens=False)"
   ],
   "id": "25b887ed3192c44a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Chunks: 1270\n",
      "\n",
      " ================================================== 200th Chunk ================================================== \n",
      " When tea was over Mr. Hurst reminded his sister-in-law of the\n",
      "card-table--but in vain. She had obtained private intelligence that Mr.\n",
      "Darcy did not wish for cards, and Mr. Hurst soon found even his open\n",
      "petition rejected. She assured him that no one intended to play, and the\n",
      "silence of the whole party on the subject seemed to justify her. Mr.\n",
      "Hurst had, therefore, nothing to do but to stretch himself on one of the\n",
      "sofas and go to sleep. Darcy took up a book. Miss Bingley did the same;\n",
      "and Mrs. Hurst, principally occupied in playing with her bracelets and\n",
      "rings, joined now and then in her brother’s conversation with Miss\n",
      "Bennet.\n",
      "\n",
      " ================================================== 201st Chunk ================================================== \n",
      " Miss Bingley’s attention was quite as much engaged in watching Mr.\n",
      "Darcy’s progress through _his_ book, as in reading her own; and she was\n",
      "perpetually either making some inquiry, or looking at his page. She\n",
      "could not win him, however, to any conversation; he merely answered her\n",
      "question and read on. At length, quite exhausted by the attempt to be\n",
      "amused with her own book, which she had only chosen because it was the\n",
      "second volume of his, she gave a great yawn and said, “How pleasant it\n",
      "is to spend an evening in this way! I declare, after all, there is no\n",
      "enjoyment like reading! How much sooner one tires of anything than of a\n",
      "book! When I have a house of my own, I shall be miserable if I have not\n",
      "an excellent library.”\n",
      "\n",
      "No character overlap found\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:51:59.338085Z",
     "start_time": "2025-05-27T06:51:59.330015Z"
    }
   },
   "cell_type": "code",
   "source": "len(recursive_character_chunks[199]) # Chunk 200",
   "id": "c8673060844d8f57",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This means we don't get exact splits - a chunk might be 550 characters long because that's where a paragraph or sentence naturally ends, rather than forcing the full 800 character limit. The chunker prioritizes maintaining these natural text boundaries over hitting the exact maximum size.",
   "id": "2b76dcb697ee2271"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Chunk Size of `800` Characters, `400` Overlap**",
   "id": "a9950ee159199225"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:52:01.832910Z",
     "start_time": "2025-05-27T06:52:01.628134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "recursive_token_chunker = RecursiveTokenChunker(\n",
    "    chunk_size=800,  # Character Length\n",
    "    chunk_overlap=400,  # Overlap\n",
    "    length_function=openai_token_count,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"?\", \"!\", \" \", \"\"] # According to Research\n",
    ")\n",
    "\n",
    "recursive_token_overlap_chunks = recursive_token_chunker.split_text(document)\n",
    "\n",
    "analyze_chunks(recursive_token_overlap_chunks, use_tokens=True)"
   ],
   "id": "b54961cc8c3d80bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Chunks: 427\n",
      "\n",
      " ================================================== 200th Chunk ================================================== \n",
      " “I do not mean to say that a woman may not be settled too near her\n",
      "family. The far and the near must be relative, and depend on many\n",
      "varying circumstances. Where there is fortune to make the expense of\n",
      "travelling unimportant, distance becomes no evil. But that is not the\n",
      "case _here_. Mr. and Mrs. Collins have a comfortable income, but not\n",
      "such a one as will allow of frequent journeys--and I am persuaded my\n",
      "friend would not call herself _near_ her family under less than _half_\n",
      "the present distance.”\n",
      "\n",
      "Mr. Darcy drew his chair a little towards her, and said, “_You_ cannot\n",
      "have a right to such very strong local attachment. _You_ cannot have\n",
      "been always at Longbourn.”\n",
      "\n",
      "Elizabeth looked surprised. The gentleman experienced some change of\n",
      "feeling; he drew back his chair, took a newspaper from the table, and,\n",
      "glancing over it, said, in a colder voice,--\n",
      "\n",
      "“Are you pleased with Kent?”\n",
      "\n",
      "A short dialogue on the subject of the country ensued, on either side\n",
      "calm and concise--and soon put an end to by the entrance of Charlotte\n",
      "and her sister, just returned from their walk. The _tête-à-tête_\n",
      "surprised them. Mr. Darcy related the mistake which had occasioned his\n",
      "intruding on Miss Bennet, and, after sitting a few minutes longer,\n",
      "without saying much to anybody, went away.\n",
      "\n",
      "[Illustration: “Accompanied by their aunt”\n",
      "\n",
      "[_Copyright 1894 by George Allen._]]\n",
      "\n",
      "“What can be the meaning of this?” said Charlotte, as soon as he was\n",
      "gone. “My dear Eliza, he must be in love with you, or he would never\n",
      "have called on us in this familiar way.”\n",
      "\n",
      "But when Elizabeth told of his silence, it did not seem very likely,\n",
      "even to Charlotte’s wishes, to be the case; and, after various\n",
      "conjectures, they could at last only suppose his visit to proceed from\n",
      "the difficulty of finding anything to do, which was the more probable\n",
      "from the time of year. All field sports were over. Within doors there\n",
      "was Lady Catherine, books, and a billiard table, but gentlemen cannot be\n",
      "always within doors; and in the nearness of the Parsonage, or the\n",
      "pleasantness of the walk to it, or of the people who lived in it, the\n",
      "two cousins found a temptation from this period of walking thither\n",
      "almost every day. They called at various times of the morning, sometimes\n",
      "separately, sometimes together, and now and then accompanied by their\n",
      "aunt. It was plain to them all that Colonel Fitzwilliam came because he\n",
      "had pleasure in their society, a persuasion which of course recommended\n",
      "him still more; and Elizabeth was reminded by her own satisfaction in\n",
      "being with him, as well as by his evident admiration, of her former\n",
      "favourite, George Wickham; and though, in comparing them, she saw there\n",
      "was less captivating softness in Colonel Fitzwilliam’s manners, she\n",
      "believed he might have the best informed mind.\n",
      "\n",
      " ================================================== 201st Chunk ================================================== \n",
      " [Illustration: “Accompanied by their aunt”\n",
      "\n",
      "[_Copyright 1894 by George Allen._]]\n",
      "\n",
      "“What can be the meaning of this?” said Charlotte, as soon as he was\n",
      "gone. “My dear Eliza, he must be in love with you, or he would never\n",
      "have called on us in this familiar way.”\n",
      "\n",
      "But when Elizabeth told of his silence, it did not seem very likely,\n",
      "even to Charlotte’s wishes, to be the case; and, after various\n",
      "conjectures, they could at last only suppose his visit to proceed from\n",
      "the difficulty of finding anything to do, which was the more probable\n",
      "from the time of year. All field sports were over. Within doors there\n",
      "was Lady Catherine, books, and a billiard table, but gentlemen cannot be\n",
      "always within doors; and in the nearness of the Parsonage, or the\n",
      "pleasantness of the walk to it, or of the people who lived in it, the\n",
      "two cousins found a temptation from this period of walking thither\n",
      "almost every day. They called at various times of the morning, sometimes\n",
      "separately, sometimes together, and now and then accompanied by their\n",
      "aunt. It was plain to them all that Colonel Fitzwilliam came because he\n",
      "had pleasure in their society, a persuasion which of course recommended\n",
      "him still more; and Elizabeth was reminded by her own satisfaction in\n",
      "being with him, as well as by his evident admiration, of her former\n",
      "favourite, George Wickham; and though, in comparing them, she saw there\n",
      "was less captivating softness in Colonel Fitzwilliam’s manners, she\n",
      "believed he might have the best informed mind.\n",
      "\n",
      "But why Mr. Darcy came so often to the Parsonage it was more difficult\n",
      "to understand. It could not be for society, as he frequently sat there\n",
      "ten minutes together without opening his lips; and when he did speak, it\n",
      "seemed the effect of necessity rather than of choice--a sacrifice to\n",
      "propriety, not a pleasure to himself. He seldom appeared really\n",
      "animated. Mrs. Collins knew not what to make of him. Colonel\n",
      "Fitzwilliam’s occasionally laughing at his stupidity proved that he was\n",
      "generally different, which her own knowledge of him could not have told\n",
      "her; and as she would have liked to believe this change the effect of\n",
      "love, and the object of that love her friend Eliza, she set herself\n",
      "seriously to work to find it out: she watched him whenever they were at\n",
      "Rosings, and whenever he came to Hunsford; but without much success. He\n",
      "certainly looked at her friend a great deal, but the expression of that\n",
      "look was disputable. It was an earnest, steadfast gaze, but she often\n",
      "doubted whether there were much admiration in it, and sometimes it\n",
      "seemed nothing but absence of mind.\n",
      "\n",
      "She had once or twice suggested to Elizabeth the possibility of his\n",
      "being partial to her, but Elizabeth always laughed at the idea; and Mrs.\n",
      "Collins did not think it right to press the subject, from the danger of\n",
      "raising expectations which might only end in disappointment; for in her\n",
      "opinion it admitted not of a doubt, that all her friend’s dislike would\n",
      "vanish, if she could suppose him to be in her power.\n",
      "\n",
      "In her kind schemes for Elizabeth, she sometimes planned her marrying\n",
      "Colonel Fitzwilliam. He was, beyond comparison, the pleasantest man: he\n",
      "certainly admired her, and his situation in life was most eligible; but,\n",
      "to counterbalance these advantages, Mr. Darcy had considerable patronage\n",
      "in the church, and his cousin could have none at all.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[Illustration: “On looking up”]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CHAPTER XXXIII.\n",
      "\n",
      "\n",
      "[Illustration]\n",
      "\n",
      "No token overlap found\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### <font color='orange'>**Greg Kamradt Semantic Chunker**</font>",
   "id": "e634b527ae4f7aa1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Greg Kamradt popularized what's known as the semantic chunker with his 5 Levels of Text Splitting notebook here which takes a different approach from fixed character/token chunking. Instead of splitting text at predetermined positions or separators, it uses embeddings to find natural semantic boundaries in the text while maintaining consistent chunk sizes.\n",
    "\n",
    "Chroma modified the algorithm to provide better size control through binary search. The chunker first splits text into small fixed-size pieces (around 50 tokens) using standard recursive splitting with separators. For each piece, it looks at surrounding context (3 segments before and after) to understand the local meaning - this helps maintain semantic coherence across potential split points.\n",
    "\n",
    "After embedding these contextualized pieces, it calculates cosine distances between consecutive segments. Higher distances suggest natural topic transitions that make good splitting points. But rather than using Kamradt's original fixed percentile approach for choosing split points, Chroma's version uses binary search to find a similarity threshold that produces chunks close to the target size.\n",
    "\n",
    "The binary search starts with limits of 0.0 and 1.0, calculating the midpoint threshold and counting how many splits it would create. If there are too many splits, it raises the threshold by adjusting the lower limit; too few splits, it lowers the threshold by adjusting the upper limit. This continues until it finds a threshold that creates chunks of approximately the desired size.\n",
    "\n",
    "This modification makes the chunker more practical by balancing semantic coherence with consistent chunk sizes. While the original version could produce unpredictably large chunks, the modified version maintains better size control while still respecting natural topic boundaries in the text."
   ],
   "id": "aaffb57baa81acbe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:52:09.076359Z",
     "start_time": "2025-05-27T06:52:08.909159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Helper Function from the Repo that Returns Embeddings\n",
    "embedding_function = embedding_functions.OpenAIEmbeddingFunction(api_key=os.environ[\"OPENAI_API_KEY\"], model_name=\"text-embedding-3-large\")"
   ],
   "id": "51e4a7cbfd2e96f9",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T19:41:47.102972Z",
     "start_time": "2025-05-25T19:41:32.232269Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install langchain_experimental langchain_openai",
   "id": "579ba7add53e7a57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_experimental\n",
      "  Using cached langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.3.18-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-community<0.4.0,>=0.3.0 (from langchain_experimental)\n",
      "  Using cached langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.28 (from langchain_experimental)\n",
      "  Downloading langchain_core-0.3.61-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain<1.0.0,>=0.3.25 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached sqlalchemy-2.0.41-cp311-cp311-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Downloading aiohttp-3.12.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached langsmith-0.3.42-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.2.6)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached frozenlist-1.6.0-cp311-cp311-win_amd64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Downloading multidict-6.4.4-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached propcache-0.3.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached yarl-1.20.0-cp311-cp311-win_amd64.whl.metadata (74 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.25->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.25->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.11.4)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.28->langchain_experimental)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<0.4.0,>=0.3.28->langchain_experimental)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.28->langchain_experimental) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10.18)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached zstandard-0.23.0-cp311-cp311-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: anyio in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (4.9.0)\n",
      "Requirement already satisfied: certifi in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.4.0)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached greenlet-3.2.2-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from langchain_openai) (1.81.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: colorama in d:\\aievolution\\my-llm-playground\\chunking\\the-best-way-to-chunk-text-for-rag\\venv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain_openai) (0.4.6)\n",
      "Using cached langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
      "Using cached langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
      "Downloading aiohttp-3.12.0-cp311-cp311-win_amd64.whl (439 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "Downloading langchain_core-0.3.61-py3-none-any.whl (438 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Using cached langsmith-0.3.42-py3-none-any.whl (360 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.4.4-cp311-cp311-win_amd64.whl (38 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached sqlalchemy-2.0.41-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.20.0-cp311-cp311-win_amd64.whl (93 kB)\n",
      "Using cached zstandard-0.23.0-cp311-cp311-win_amd64.whl (495 kB)\n",
      "Downloading langchain_openai-0.3.18-py3-none-any.whl (63 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.6.0-cp311-cp311-win_amd64.whl (120 kB)\n",
      "Using cached greenlet-3.2.2-cp311-cp311-win_amd64.whl (295 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached propcache-0.3.1-cp311-cp311-win_amd64.whl (45 kB)\n",
      "Installing collected packages: zstandard, propcache, packaging, mypy-extensions, multidict, jsonpatch, httpx-sse, greenlet, frozenlist, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, requests-toolbelt, marshmallow, aiosignal, pydantic-settings, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain_openai, langchain, langchain-community, langchain_experimental\n",
      "\n",
      "  Attempting uninstall: packaging\n",
      "\n",
      "    Found existing installation: packaging 25.0\n",
      "\n",
      "    Uninstalling packaging-25.0:\n",
      "\n",
      "      Successfully uninstalled packaging-25.0\n",
      "\n",
      "   ------- --------------------------------  5/26 [jsonpatch]\n",
      "   ---------------- ----------------------- 11/26 [typing-inspect]\n",
      "   ------------------ --------------------- 12/26 [SQLAlchemy]\n",
      "   ------------------ --------------------- 12/26 [SQLAlchemy]\n",
      "   ------------------ --------------------- 12/26 [SQLAlchemy]\n",
      "   ------------------ --------------------- 12/26 [SQLAlchemy]\n",
      "   ------------------ --------------------- 12/26 [SQLAlchemy]\n",
      "   ------------------ --------------------- 12/26 [SQLAlchemy]\n",
      "   -------------------- ------------------- 13/26 [requests-toolbelt]\n",
      "   -------------------------- ------------- 17/26 [langsmith]\n",
      "   ----------------------------- ---------- 19/26 [aiohttp]\n",
      "   ------------------------------ --------- 20/26 [langchain-core]\n",
      "   ------------------------------ --------- 20/26 [langchain-core]\n",
      "   ------------------------------ --------- 20/26 [langchain-core]\n",
      "   ----------------------------------- ---- 23/26 [langchain]\n",
      "   ----------------------------------- ---- 23/26 [langchain]\n",
      "   ----------------------------------- ---- 23/26 [langchain]\n",
      "   ----------------------------------- ---- 23/26 [langchain]\n",
      "   ----------------------------------- ---- 23/26 [langchain]\n",
      "   ----------------------------------- ---- 23/26 [langchain]\n",
      "   ----------------------------------- ---- 23/26 [langchain]\n",
      "   ----------------------------------- ---- 23/26 [langchain]\n",
      "   ----------------------------------- ---- 23/26 [langchain]\n",
      "   ------------------------------------ --- 24/26 [langchain-community]\n",
      "   ------------------------------------ --- 24/26 [langchain-community]\n",
      "   ------------------------------------ --- 24/26 [langchain-community]\n",
      "   ------------------------------------ --- 24/26 [langchain-community]\n",
      "   ------------------------------------ --- 24/26 [langchain-community]\n",
      "   ------------------------------------ --- 24/26 [langchain-community]\n",
      "   ------------------------------------ --- 24/26 [langchain-community]\n",
      "   ------------------------------------ --- 24/26 [langchain-community]\n",
      "   ------------------------------------ --- 24/26 [langchain-community]\n",
      "   ------------------------------------ --- 24/26 [langchain-community]\n",
      "   ------------------------------------ --- 24/26 [langchain-community]\n",
      "   ------------------------------------ --- 24/26 [langchain-community]\n",
      "   ------------------------------------ --- 24/26 [langchain-community]\n",
      "   -------------------------------------- - 25/26 [langchain_experimental]\n",
      "   ---------------------------------------- 26/26 [langchain_experimental]\n",
      "\n",
      "Successfully installed SQLAlchemy-2.0.41 aiohappyeyeballs-2.6.1 aiohttp-3.12.0 aiosignal-1.3.2 dataclasses-json-0.6.7 frozenlist-1.6.0 greenlet-3.2.2 httpx-sse-0.4.0 jsonpatch-1.33 langchain-0.3.25 langchain-community-0.3.24 langchain-core-0.3.61 langchain-text-splitters-0.3.8 langchain_experimental-0.3.4 langchain_openai-0.3.18 langsmith-0.3.42 marshmallow-3.26.1 multidict-6.4.4 mypy-extensions-1.1.0 packaging-24.2 propcache-0.3.1 pydantic-settings-2.9.1 requests-toolbelt-1.0.0 typing-inspect-0.9.0 yarl-1.20.0 zstandard-0.23.0\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:52:42.258678Z",
     "start_time": "2025-05-27T06:52:13.803186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "lc_semantic_chunker = SemanticChunker(OpenAIEmbeddings())\n",
    "\n",
    "lc_semantic_chunks = lc_semantic_chunker.create_documents([document])"
   ],
   "id": "2a711443afddfc4",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:52:45.630853Z",
     "start_time": "2025-05-27T06:52:45.625983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(\"# of Chunks:\", len(lc_semantic_chunks), \"\\n\")\n",
    "print(lc_semantic_chunks[199].page_content)\n",
    "print(\"\\n\\n\", \"=\"*50, \"\\n\\n\")\n",
    "print(lc_semantic_chunks[200].page_content)\n",
    "print(\"\\n\\n\", \"=\"*50, \"\\n\\n\")\n",
    "\n",
    "count_tokens(lc_semantic_chunks[199].page_content)\n",
    "count_tokens(lc_semantic_chunks[200].page_content)"
   ],
   "id": "6180ac779534b3ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Chunks: 305 \n",
      "\n",
      "“John told us Mr. Darcy was\n",
      "here when you sent for us;--was it so?”\n",
      "\n",
      "“Yes; and I told him we should not be able to keep our engagement. _That_ is all settled.”\n",
      "\n",
      "“What is all settled?” repeated the other, as she ran into her room to\n",
      "prepare. “And are they upon such terms as for her to disclose the real\n",
      "truth? Oh, that I knew how it was!”\n",
      "\n",
      "But wishes were vain; or, at best, could serve only to amuse her in the\n",
      "hurry and confusion of the following hour. Had Elizabeth been at leisure\n",
      "to be idle, she would have remained certain that all employment was\n",
      "impossible to one so wretched as herself; but she had her share of\n",
      "business as well as her aunt, and amongst the rest there were notes to\n",
      "be written to all their friends at Lambton, with false excuses for their\n",
      "sudden departure. An hour, however, saw the whole completed; and Mr. Gardiner, meanwhile, having settled his account at the inn, nothing\n",
      "remained to be done but to go; and Elizabeth, after all the misery of\n",
      "the morning, found herself, in a shorter space of time than she could\n",
      "have supposed, seated in the carriage, and on the road to Longbourn. [Illustration:\n",
      "\n",
      "     “The first pleasing earnest of their welcome”\n",
      "]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CHAPTER XLVII. [Illustration]\n",
      "\n",
      "“I have been thinking it over again, Elizabeth,” said her uncle, as they\n",
      "drove from the town; “and really, upon serious consideration, I am much\n",
      "more inclined than I was to judge as your eldest sister does of the\n",
      "matter. It appears to me so very unlikely that any young man should form\n",
      "such a design against a girl who is by no means unprotected or\n",
      "friendless, and who was actually staying in his Colonel’s family, that I\n",
      "am strongly inclined to hope the best. Could he expect that her friends\n",
      "would not step forward? Could he expect to be noticed again by the\n",
      "regiment, after such an affront to Colonel Forster? His temptation is\n",
      "not adequate to the risk.”\n",
      "\n",
      "“Do you really think so?” cried Elizabeth, brightening up for a moment. “Upon my word,” said Mrs. Gardiner, “I begin to be of your uncle’s\n",
      "opinion. It is really too great a violation of decency, honour, and\n",
      "interest, for him to be guilty of it. I cannot think so very ill of\n",
      "Wickham. Can you, yourself, Lizzie, so wholly give him up, as to believe\n",
      "him capable of it?”\n",
      "\n",
      "“Not perhaps of neglecting his own interest. But of every other neglect\n",
      "I can believe him capable. If, indeed, it should be so!\n",
      "\n",
      "\n",
      " ================================================== \n",
      "\n",
      "\n",
      "But I dare not\n",
      "hope it. Why should they not go on to Scotland, if that had been the\n",
      "case?”\n",
      "\n",
      "“In the first place,” replied Mr. Gardiner, “there is no absolute proof\n",
      "that they are not gone to Scotland.”\n",
      "\n",
      "“Oh, but their removing from the chaise into a hackney coach is such a\n",
      "presumption! And, besides, no traces of them were to be found on the\n",
      "Barnet road.”\n",
      "\n",
      "“Well, then,--supposing them to be in London--they may be there, though\n",
      "for the purpose of concealment, for no more exceptionable purpose. It is\n",
      "not likely that money should be very abundant on either side; and it\n",
      "might strike them that they could be more economically, though less\n",
      "expeditiously, married in London, than in Scotland.”\n",
      "\n",
      "“But why all this secrecy? Why any fear of detection? Why must their\n",
      "marriage be private? Oh, no, no--this is not likely. His most particular\n",
      "friend, you see by Jane’s account, was persuaded of his never intending\n",
      "to marry her. Wickham will never marry a woman without some money. He\n",
      "cannot afford it. And what claims has Lydia, what attractions has she\n",
      "beyond youth, health, and good humour, that could make him for her sake\n",
      "forego every chance of benefiting himself by marrying well? As to what\n",
      "restraint the apprehensions of disgrace in the corps might throw on a\n",
      "dishonourable elopement with her, I am not able to judge; for I know\n",
      "nothing of the effects that such a step might produce. But as to your\n",
      "other objection, I am afraid it will hardly hold good. Lydia has no\n",
      "brothers to step forward; and he might imagine, from my father’s\n",
      "behaviour, from his indolence and the little attention he has ever\n",
      "seemed to give to what was going forward in his family, that _he_ would\n",
      "do as little and think as little about it, as any father could do, in\n",
      "such a matter.”\n",
      "\n",
      "“But can you think that Lydia is so lost to everything but love of him,\n",
      "as to consent to live with him on any other terms than marriage?”\n",
      "\n",
      "“It does seem, and it is most shocking, indeed,” replied Elizabeth, with\n",
      "tears in her eyes, “that a sister’s sense of decency and virtue in such\n",
      "a point should admit of doubt. But, really, I know not what to say.\n",
      "\n",
      "\n",
      " ================================================== \n",
      "\n",
      "\n",
      "Number of tokens: 577\n",
      "Number of tokens: 511\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:53:38.271572Z",
     "start_time": "2025-05-27T06:52:55.104270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kamradt_chunker = KamradtModifiedChunker(\n",
    "    avg_chunk_size=400,      # Target size in tokens\n",
    "    min_chunk_size=50,       # Initial split size\n",
    "    embedding_function=embedding_function  # Pass your embedding function\n",
    ")\n",
    "\n",
    "# Split your text\n",
    "modified_kamradt_chunks = kamradt_chunker.split_text(document)"
   ],
   "id": "73cab7556fda9e3d",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:53:42.097884Z",
     "start_time": "2025-05-27T06:53:42.092598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "analyze_chunks(modified_kamradt_chunks, use_tokens=True)\n",
    "print(\"\\n\\n\", \"=\"*50, \"\\n\\n\")\n",
    "count_tokens(modified_kamradt_chunks[200])"
   ],
   "id": "f17fb3e53c90e9e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Chunks: 434\n",
      "\n",
      " ================================================== 200th Chunk ================================================== \n",
      " family had quitted the country, he had told his story to no one but\n",
      "herself; but that after their removal, it had been everywhere discussed; that he had then no reserves, no scruples in sinking Mr. Darcy’s\n",
      "character, though he had assured her that respect for the father would\n",
      "always prevent his exposing the son. How differently did everything now appear in which he was concerned! His\n",
      "attentions to Miss King were now the consequence of views solely and\n",
      "hatefully mercenary; and the mediocrity of her fortune proved no longer the moderation of his wishes, but his eagerness to grasp at anything.\n",
      "His behaviour to herself could now have had no tolerable motive: he had\n",
      "either been deceived with regard to her fortune, or had been gratifying his vanity by encouraging the preference which she believed she had most\n",
      "incautiously shown. Every lingering struggle in his favour grew fainter\n",
      "and fainter; and in further justification of Mr. Darcy, she could not but allow that Mr. Bingley, when questioned by Jane, had long ago\n",
      "asserted his blamelessness in the affair;--that, proud and repulsive as were his manners, she had never, in the whole course of their\n",
      "acquaintance--an acquaintance which had latterly brought them much\n",
      "together, and given her a sort of intimacy with his ways--seen anything that betrayed him to be unprincipled or unjust--anything that spoke him\n",
      "of irreligious or immoral habits;--that among his own connections he was\n",
      "esteemed and valued;--that even Wickham had allowed him merit as a brother, and that she had often heard him speak so affectionately of his\n",
      "sister as to prove him capable of some amiable feeling;--that had his\n",
      "actions been what Wickham represented them, so gross a violation of everything right could hardly have been concealed from the world; and\n",
      "that friendship between a person capable of it and such an amiable man\n",
      "as Mr. Bingley was incomprehensible. She grew absolutely ashamed of herself. Of neither Darcy nor Wickham\n",
      "could she think, without feeling that she had been blind, partial,\n",
      "prejudiced, absurd. “How despicably have I acted!” she cried. “I, who have prided myself on\n",
      "my discernment! I, who have valued myself on my abilities! who have often disdained the generous candour of my sister, and gratified my\n",
      "vanity in useless or blameless distrust. How humiliating is this discovery! Yet, how just a humiliation! Had I been in love, I could not\n",
      "have been more wretchedly blind. But vanity, not love, has been my folly. Pleased with the preference of one, and offended by the neglect\n",
      "of the other, on the very beginning of our acquaintance, I have courted\n",
      "prepossession and ignorance, and driven reason away where either were concerned. Till this moment, I never knew myself.” From herself to Jane, from Jane to Bingley, her thoughts were in a line\n",
      "which soon brought to her recollection that Mr. Darcy’s explanation _there_ had appeared very insufficient; and she read it again. Widely\n",
      "different was the effect of a second perusal. How could she deny that\n",
      "credit to his assertions, in one instance, which she had been obliged to give in the other? He declared himself to have been totally unsuspicious\n",
      "of her sister’s attachment; and she could not help remembering what\n",
      "Charlotte’s opinion had always been. Neither could she deny the justice of his description of Jane. She felt that Jane’s feelings, though\n",
      "fervent, were little displayed, and that there was a constant\n",
      "complacency in her air and manner, not often united with great\n",
      "sensibility. When she came to that part of the letter in which her family were\n",
      "mentioned, in tones of such mortifying, yet merited, reproach, her sense\n",
      "of shame was severe. The justice of the charge struck her too forcibly\n",
      "\n",
      " ================================================== 201st Chunk ================================================== \n",
      " for denial; and the circumstances to which he particularly alluded, as\n",
      "having passed at the Netherfield ball, and as confirming all his first\n",
      "disapprobation, could not have made a stronger impression on his mind\n",
      "\n",
      "No token overlap found\n",
      "\n",
      "\n",
      " ================================================== \n",
      "\n",
      "\n",
      "Number of tokens: 46\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### <font color='orange'>**Cluster Semantic Chunker**</font>",
   "id": "5f2d94859d427289"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The ClusterSemanticChunker takes a **global optimization** approach to chunking, contrasting with kamradt's **local decisions** about split points. Rather than looking through a sliding window of context, it considers relationships between all pieces of text simultaneously to find the most semantically coherent groupings while maintaining size constraints.\n",
    "\n",
    "The process begins similar to other chunkers by splitting text into small fixed-size pieces (defaulting to around 50 tokens) using standard recursive splitting. However, instead of only analyzing consecutive pieces, it creates a similarity matrix by embedding each piece and calculating cosine similarities between all possible pairs. This gives the chunker a complete view of semantic relationships throughout the document.\n",
    "\n",
    "Using this similarity matrix, the chunker employs dynamic programming to find the optimal way to group pieces into chunks. For each position in the text, it tries different possible chunk sizes and calculates a \"reward\" based on the total semantic similarity between all pieces within that potential chunk. By building up from small pieces and saving intermediate results, it efficiently explores the space of possible chunkings to find a global optimum.\n",
    "\n",
    "The size constraints are enforced by limiting the maximum number of pieces that can be combined into a chunk (max_cluster). Within this limit, the algorithm is free to create chunks that maximize semantic coherence. This leads to more natural groupings than approaches that only look at local context, as it can recognize when pieces far apart in the text are actually closely related.\n",
    "\n",
    "This global optimization strategy helps avoid some common pitfalls of sliding window approaches. While local methods might miss opportunities to group related content that's separated by a brief topic shift, the cluster approach can see these relationships in its similarity matrix. The result is chunks that more accurately reflect the semantic structure of the document while still maintaining practical size limits for downstream processing."
   ],
   "id": "7f4b83eaad5c2b6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T06:54:22.827140Z",
     "start_time": "2025-05-27T06:53:45.750601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cluster_chunker = ClusterSemanticChunker(\n",
    "    embedding_function=embedding_function,\n",
    "    max_chunk_size=400,\n",
    "    length_function=openai_token_count\n",
    ")\n",
    "\n",
    "cluster_chunker_chunks = cluster_chunker.split_text(document)\n",
    "\n",
    "analyze_chunks(cluster_chunker_chunks, use_tokens=True)"
   ],
   "id": "ca62e26542b0d8a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Chunks: 1000\n",
      "\n",
      " ================================================== 200th Chunk ================================================== \n",
      " “WILLIAM COLLINS.”\n",
      "\n",
      " ================================================== 201st Chunk ================================================== \n",
      " “At four o’clock, therefore, we may expect this peace-making gentleman,”\n",
      "said Mr. Bennet, as he folded up the letter. “He seems to be a most\n",
      "\n",
      "No token overlap found\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### <font color='orange'>**LLM Semantic Chunker**</font>",
   "id": "2ad36d2bdc495e24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The LLM Semantic Chunker takes a direct approach to document chunking by literally asking a Language Model to identify semantic boundaries. The process begins by dividing the input text into small, fixed-size pieces of around 50 tokens using a standard recursive splitter, creating manageable units for the LLM to analyze. These pieces are then wrapped with special tags like `<start_chunk_1>` and `<end_chunk_1>` to maintain their identity throughout the process.\n",
    "\n",
    "The core of the chunking process involves presenting text to the LLM in windows of approximately 800 tokens (containing multiple small pieces) at a time. For each window, the LLM is instructed to identify natural semantic breaks, responding in a specific format like `split_after: X, Y, Z` where X, Y, Z are chunk numbers. These splits must be in ascending order and must start from the current position, with at least one split being required to ensure the process continues moving forward.\n",
    "\n",
    "The chunker maintains a sliding window approach, progressively moving through the document based on the LLM's last suggested split point. This continues until either the end of the document is reached or the remaining text becomes too short to require further splitting (less than ~4 chunks). The suggested split points are then used to reassemble the small pieces into final chunks, with each chunk combining all pieces between two split points.\n",
    "\n",
    "Internally, the system prompt follows:\n",
    "\n",
    "<font color='red' >\"You are an assistant specialized in splitting text into thematically consistent sections. \"\n",
    "\"The text has been divided into chunks, each marked with <|start_chunk_X|> and <|end_chunk_X|> tags, where X is the chunk number. \"\n",
    "\"Your task is to identify the points where splits should occur, such that consecutive chunks of similar themes stay together. \"\n",
    "\"Respond with a list of chunk IDs where you believe a split should be made. For example, if chunks 1 and 2 belong together but chunk 3 starts a new topic, you would suggest a split after chunk 2. THE CHUNKS MUST BE IN ASCENDING ORDER.\"\n",
    "\"Your response should be in the form: 'split_after: 3, 5'.\"</font>"
   ],
   "id": "17566a8b2dddcde3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T07:12:23.139477Z",
     "start_time": "2025-05-27T07:09:09.110701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm_chunker = LLMSemanticChunker(\n",
    "    organisation=\"openai\",\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "llm_chunker_chunks = llm_chunker.split_text(document)\n",
    "\n",
    "analyze_chunks(llm_chunker_chunks, use_tokens=True)"
   ],
   "id": "f643e62c313ca1a2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|██████████| 4871/4871 [03:13<00:00, 25.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Chunks: 700\n",
      "\n",
      " ================================================== 200th Chunk ================================================== \n",
      " the polite inquiries which he directly afterwards approached to make.\n",
      "Attention, forbearance, patience with Darcy, was injury to Wickham. She\n",
      "was resolved against any sort of conversation with him, and turned away with a degree of ill-humour which she could not wholly surmount even in\n",
      "speaking to Mr. Bingley, whose blind partiality provoked her.\n",
      "\n",
      " ================================================== 201st Chunk ================================================== \n",
      " But Elizabeth was not formed for ill-humour; and though every prospect\n",
      "of her own was destroyed for the evening, it could not dwell long on her spirits; and, having told all her griefs to Charlotte Lucas, whom she\n",
      "had not seen for a week, she was soon able to make a voluntary\n",
      "\n",
      "No token overlap found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "97160538f88c6209"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
